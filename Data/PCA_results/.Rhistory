y = "word count",
x = "sentiment")
gt
dg <- Gerhardt %>% count(value)
gd <- ggplot(data = dg, aes(value, n)) +
geom_col() +
coord_flip() +
theme_clean() +
labs(title = "Number of Words in Each sentiment category by Gerhardt",
caption = "Data from webroboto.io â€˜s repository (the most recent crawl on 2021-03-18)",
tag = "Figure 2",
y = "word count",
x = "sentiment")
gd
# drop all the footnotes (after a smaller font size integer)
# apply to all pages
for (i in 1:length(Turley))
{
n_footnote <- Turley[[i]] %>%
mutate(index = row_number()) %>%
filter(font_size == "7.92") %>%
nrow()
if (n_footnote != 0) {
foot_start <- new$index[n_footnote/2 + 1]
foot_start
Turley[[i]] <- Turley[[i]] %>%
mutate(index = row_number()) %>%
filter(index < foot_start)
}
}
knitr::opts_chunk$set(echo = TRUE)
Turley <- pdftools::pdf_data("https://tinyurl.com/4Turley", font_info = TRUE)
library(dplyr)
library(tidyverse)
library(tidymodels)
library(tidytext)
library(ggplot2)
library(ggthemes)
# drop all the footnotes (after a smaller font size integer)
# apply to all pages
for (i in 1:length(Turley))
{
n_footnote <- Turley[[i]] %>%
mutate(index = row_number()) %>%
filter(font_size == "7.92") %>%
nrow()
if (n_footnote != 0) {
foot_start <- new$index[n_footnote/2 + 1]
foot_start
Turley[[i]] <- Turley[[i]] %>%
mutate(index = row_number()) %>%
filter(index < foot_start)
}
}
print(i)
# drop all the footnotes (after a smaller font size integer)
# apply to all pages
for (i in 1:length(Turley))
{
n_footnote <- Turley[[i]] %>%
mutate(index = row_number()) %>%
filter(font_size == "7.92") %>%
nrow()
if (n_footnote != 0) {
foot_start <- new$index[n_footnote/2 + 1]
foot_start
Turley[[i]] <- Turley[[i]] %>%
mutate(index = row_number()) %>%
filter(index < foot_start)
}
print(i)
}
n_footnote <- Turley[[i]] %>%
mutate(index = row_number()) %>%
filter(font_size == "7.92") %>%
nrow()
if (n_footnote != 0) {
foot_start <- new$index[n_footnote/2 + 1]
foot_start
Turley[[i]] <- Turley[[i]] %>%
mutate(index = row_number()) %>%
filter(index < foot_start)
}
new <- Turley[[i]] %>%
mutate(index = row_number())
n_footnote <- new %>%
filter(font_size == "7.92") %>%
nrow()
if (n_footnote != 0) {
foot_start <- new$index[n_footnote/2 + 1]
foot_start
Turley[[i]] <- Turley[[i]] %>%
mutate(index = row_number()) %>%
filter(index < foot_start)
}
if (n_footnote != 0) {
foot_start <- new$index[n_footnote/2 + 1]
foot_start
Turley[[i]] <- Turley[[i]] %>%
mutate(index = row_number()) %>%
filter(index < foot_start)
}
print(i)
# drop all the footnotes (after a smaller font size integer)
# apply to all pages
for (i in 1:length(Turley))
{
new <- Turley[[i]] %>%
mutate(index = row_number())
n_footnote <- new %>%
filter(font_size == "7.92") %>%
nrow()
if (n_footnote != 0) {
foot_start <- new$index[n_footnote/2 + 1]
foot_start
Turley[[i]] <- Turley[[i]] %>%
mutate(index = row_number()) %>%
filter(index < foot_start)
}
print(i)
}
# see if it worked -- yes
# summary(Turley[[1]])
# combine the pages into a single data.frame
Turley <- bind_rows(Turley)
typeof(Turley)
install.packages("qgraph")
# QAP correlation between two networks
setwd("../../Data/")
# QAP correlation between two networks
setwd("../../../Data/")
# QAP correlation between two networks
setwd("../../Data/")
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
# 1. coefficient matrix
# Indonesia coefficient matrix
load("/Users/hailey/Documents/GitHub/G5055_Practicum_Project2/Data/coefficient_network/indo_coefficient_net_weighted.RData")
indo_cm <- cm
# Guatemala coefficient matrix
load("/Users/hailey/Documents/GitHub/G5055_Practicum_Project2/Data/coefficient_network/gua_coefficient_net_weighted.RData")
gua_cm <- cm
# 2. text similarity matrix
load("/Users/hailey/Documents/GitHub/G5055_Practicum_Project2/Data/Text_Model_Data/text_matrix.RData")
tm <- m
indo_cm[indo_cm >= -0.5 & indo_cm < 0.5] <- 0
indo_cm[indo_cm <= -0.5 | indo_cm >= 0.5] <- 1
gua_cm[gua_cm >= -0.5 & gua_cm < 0.5] <- 0
gua_cm[gua_cm <= -0.5 | gua_cm >= 0.5] <- 1
tm[tm < 0.2] <- 0
tm[tm >= 0.2] <- 1
# get the matrices in same shape and indicator order
# rownames(tm) # the whole list
indo_tm <- tm[rownames(indo_cm), rownames(indo_cm)]
# install.packages("sna")
library(sna)
indo_nl_ct <- netlm(indo_cm, indo_tm)
summary(indo_nl_ct)
# indo_nl_tc <- netlm(indo_tm, indo_cm)
# summary(indo_nl_tc)
indo_nlo_ct <- netlogit(indo_cm, indo_tm, test.statistic = "z-value")
summary(indo_nlo_ct)
indo_nlo_ct <- netlogit(indo_cm, indo_tm)
summary(indo_nlo_ct)
indo_nlo_ct <- netlogit(indo_cm, indo_tm, test.statistic = "beta")
summary(indo_nlo_ct)
# get the matrices in same shape and indicator order
# rownames(tm) # the whole list
indo_tm <- tm[rownames(indo_cm), rownames(indo_cm)]
# install.packages("sna")
library(sna)
indo_nl_ct <- netlm(indo_cm, indo_tm)
summary(indo_nl_ct)
# indo_nl_tc <- netlm(indo_tm, indo_cm)
# summary(indo_nl_tc)
tm2 <- tm[colnames(gua_cm2), colnames(gua_cm2)] # colnames(indo_cm2) and colnames(gua_cm2) are the same
# get the matrices in same shape and indicator order
# rownames(tm) # the whole list
gua_tm <- tm[rownames(gua_cm), rownames(gua_cm)]
# install.packages("sna")
library(sna)
gua_nl_tc <- netlm(gua_tm, gua_cm)
summary(gua_nl_tc)
# gua_nl_ct <- netlm(gua_cm, gua_tm)
# summary(gua_nl_ct)
gua_nlo_ct <- netlogit(gua_cm, gua_tm)
summary(gua_nlo_ct)
gua_nlo_ct <- netlogit(gua_cm, gua_tm)
summary(gua_nlo_ct)
indo_nlo_ct <- netlogit(indo_cm, indo_tm)
summary(indo_nlo_ct)
indo_nlo_ct <- netlogit(indo_cm, indo_tm)
summary(indo_nlo_ct)
# get the matrices in same shape and indicator order
# rownames(tm) # the whole list
gua_tm <- tm[rownames(gua_cm), rownames(gua_cm)]
# install.packages("sna")
library(sna)
gua_nl_tc <- netlm(gua_tm, gua_cm)
summary(gua_nl_tc)
# gua_nl_ct <- netlm(gua_cm, gua_tm)
# summary(gua_nl_ct)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(network)
library(sna)
library(dplyr)
# 1. coefficient matrix
# Indonesia coefficient matrix
load("/Users/hailey/Documents/GitHub/G5055_Practicum_Project2/Data/coefficient_network/indo_coefficient_net_weighted.RData")
indo_cm <- cm
# Guatemala coefficient matrix
load("/Users/hailey/Documents/GitHub/G5055_Practicum_Project2/Data/coefficient_network/gua_coefficient_net_weighted.RData")
gua_cm <- cm
# 2. text similarity matrix
load("/Users/hailey/Documents/GitHub/G5055_Practicum_Project2/Data/Text_Model_Data/text_matrix.RData")
tm <- m
indo_cm[indo_cm >= -0.5 & indo_cm < 0.5] <- 0
indo_cm[indo_cm <= -0.5 | indo_cm >= 0.5] <- 1
gua_cm[gua_cm >= -0.5 & gua_cm < 0.5] <- 0
gua_cm[gua_cm <= -0.5 | gua_cm >= 0.5] <- 1
tm[tm < 0.2] <- 0
tm[tm >= 0.2] <- 1
# get the matrices in same shape and indicator order
# rownames(tm) # the whole list
indo_tm <- tm[rownames(indo_cm), rownames(indo_cm)]
# install.packages("sna")
library(sna)
indo_nl_ct <- netlm(indo_cm, indo_tm)
summary(indo_nl_ct)
# indo_nl_tc <- netlm(indo_tm, indo_cm)
# summary(indo_nl_tc)
indo_nlo_ct <- netlogit(indo_cm, indo_tm)
summary(indo_nlo_ct)
# get the matrices in same shape and indicator order
# rownames(tm) # the whole list
gua_tm <- tm[rownames(gua_cm), rownames(gua_cm)]
# install.packages("sna")
library(sna)
gua_nl_tc <- netlm(gua_tm, gua_cm)
summary(gua_nl_tc)
# gua_nl_ct <- netlm(gua_cm, gua_tm)
# summary(gua_nl_ct)
gua_nlo_ct <- netlogit(gua_cm, gua_tm)
summary(gua_nlo_ct)
diff1 <- setdiff(rownames(indo_cm), rownames(gua_cm))
common_for_qap <- setdiff(rownames(indo_cm), diff1)
# diff2 <- setdiff(rownames(gua_cm), rownames(indo_cm))
# common_for_qap <- setdiff(rownames(gua_cm), diff2) # same result 87 common indicators
indo_cm2 <- indo_cm[common_for_qap, common_for_qap]
gua_cm2 <- gua_cm[common_for_qap, common_for_qap]
nl_2country <- netlm(indo_cm2, gua_cm2)
summary(nl_2country)
# nl_2country2 <- netlm(gua_cm2, indo_cm2)
# summary(nl_2country2)
nlo_2country <- netlogit(indo_cm2, gua_cm2)
summary(nlo_2country)
tm2 <- tm[colnames(gua_cm2), colnames(gua_cm2)] # colnames(indo_cm2) and colnames(gua_cm2) are the same
cm_tm <- array(NA, c(2, length(gua_cm2[1,]),length(gua_cm2[1,])))
cm_tm[1,,] <- gua_cm2
cm_tm[2,,] <- tm2
n2<-netlm(indo_cm2, cm_tm)
summary(n2)
library(network)
library(sna)
library(dplyr)
set.seed(2231)
# 1. coefficient matrix
# Indonesia coefficient matrix
load("/Users/hailey/Documents/GitHub/G5055_Practicum_Project2/Data/coefficient_network/indo_coefficient_net_weighted.RData")
indo_cm <- cm
# Guatemala coefficient matrix
load("/Users/hailey/Documents/GitHub/G5055_Practicum_Project2/Data/coefficient_network/gua_coefficient_net_weighted.RData")
gua_cm <- cm
# 2. text similarity matrix
load("/Users/hailey/Documents/GitHub/G5055_Practicum_Project2/Data/Text_Model_Data/text_matrix.RData")
tm <- m
indo_cm[indo_cm >= -0.5 & indo_cm < 0.5] <- 0
indo_cm[indo_cm <= -0.5 | indo_cm >= 0.5] <- 1
gua_cm[gua_cm >= -0.5 & gua_cm < 0.5] <- 0
gua_cm[gua_cm <= -0.5 | gua_cm >= 0.5] <- 1
tm[tm < 0.2] <- 0
tm[tm >= 0.2] <- 1
# get the matrices in same shape and indicator order
# rownames(tm) # the whole list
indo_tm <- tm[rownames(indo_cm), rownames(indo_cm)]
# install.packages("sna")
library(sna)
indo_nl_ct <- netlm(indo_cm, indo_tm)
summary(indo_nl_ct)
# indo_nl_tc <- netlm(indo_tm, indo_cm)
# summary(indo_nl_tc)
# get the matrices in same shape and indicator order
# rownames(tm) # the whole list
indo_tm <- tm[rownames(indo_cm), rownames(indo_cm)]
# install.packages("sna")
library(sna)
indo_nl_ct <- netlm(indo_cm, indo_tm)
summary(indo_nl_ct)
# indo_nl_tc <- netlm(indo_tm, indo_cm)
# summary(indo_nl_tc)
# get the matrices in same shape and indicator order
# rownames(tm) # the whole list
indo_tm <- tm[rownames(indo_cm), rownames(indo_cm)]
# install.packages("sna")
library(sna)
indo_nl_ct <- netlm(indo_cm, indo_tm)
summary(indo_nl_ct)
# indo_nl_tc <- netlm(indo_tm, indo_cm)
# summary(indo_nl_tc)
indo_nlo_ct <- netlogit(indo_cm, indo_tm)
summary(indo_nlo_ct)
tm2 <- tm[colnames(gua_cm2), colnames(gua_cm2)] # colnames(indo_cm2) and colnames(gua_cm2) are the same
cm_tm <- array(NA, c(2, length(gua_cm2[1,]),length(gua_cm2[1,])))
cm_tm[1,,] <- gua_cm2
cm_tm[2,,] <- tm2
n2<-netlm(indo_cm2, cm_tm)
summary(n2)
library(tidyverse)
mpg
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy))
?lead()
?facet_grid
remove.packages("parsnip")
remove.packages("baguette")
install.packages("parsnip")
install.packages("baguette")
remove.packages("parsnip")
remove.packages("baguette")
remotes::install_github("tidymodels/parsnip")
remove.packages("baguette")
remove.packages("parsnip")
install.packages("parsnip")
install.packages("baguette")
remove.packages("parsnip")
remove.packages("baguette")
remotes::install_github("tidymodels/parsnip")
install.packages("baguette")
remove.packages("parsnip")
remove.packages("baguette")
# load data and keep all the node pairs statistically significantly related----
setwd("/Users/hailey/Documents/GitHub/G5055_Practicum_Project2/Data/PCA_results")
# d <- read_csv("indo_coefficients.csv")
# p <- read_csv("Indonesia_scaled_correlation_among_indicators_indicator_model_pval.csv") %>% rename(Var1 = X, Var2 = Y, p = `p-unc`)
d <- read_csv("gua_coefficients.csv")
p <- read_csv("Guatemala_scaled_correlation_among_indicators_indicator_model_pval.csv") %>% rename(Var1 = X, Var2 = Y, p = `p-unc`)
d2 <- merge(d, p, by = c("Var1", "Var2"))
# change the data format to matrix, to build weighted network
library(tidyr)
library(dplyr)
el_weighted <- d2 %>%
filter(Var1 != Var2) %>%
# filter(value >= 0.5 | value <= -0.5) %>%
filter(p <= 0.05) %>%
select(Var1, Var2, value) %>%
arrange(abs(value))
library(igraph)
g2 <- graph.data.frame(el_weighted, directed = FALSE)
m <- get.adjacency(g2, sparse = FALSE, attr='value')
# load data and keep all the node pairs statistically significantly related----
setwd("/Users/hailey/Documents/GitHub/G5055_Practicum_Project2/Data/PCA_results")
# d <- read_csv("indo_coefficients.csv")
# p <- read_csv("Indonesia_scaled_correlation_among_indicators_indicator_model_pval.csv") %>% rename(Var1 = X, Var2 = Y, p = `p-unc`)
d <- read_csv("gua_coefficients.csv")
library(readr)
library(readr)
library(tidyr)
library(dplyr)
# load data and keep all the node pairs statistically significantly related----
setwd("/Users/hailey/Documents/GitHub/G5055_Practicum_Project2/Data/PCA_results")
# d <- read_csv("indo_coefficients.csv")
# p <- read_csv("Indonesia_scaled_correlation_among_indicators_indicator_model_pval.csv") %>% rename(Var1 = X, Var2 = Y, p = `p-unc`)
d <- read_csv("gua_coefficients.csv")
p <- read_csv("Guatemala_scaled_correlation_among_indicators_indicator_model_pval.csv") %>% rename(Var1 = X, Var2 = Y, p = `p-unc`)
d2 <- merge(d, p, by = c("Var1", "Var2"))
# change the data format to matrix, to build weighted network
el_weighted <- d2 %>%
filter(Var1 != Var2) %>%
# filter(value >= 0.5 | value <= -0.5) %>%
filter(p <= 0.05) %>%
select(Var1, Var2, value) %>%
arrange(abs(value))
library(igraph)
g2 <- graph.data.frame(el_weighted, directed = FALSE)
m <- get.adjacency(g2, sparse = FALSE, attr='value')
# repeat for the weighted network g2----
# some attributes----
# info <- read_csv("/Users/hailey/Documents/GitHub/G5055_Practicum_Project2/Data/processedIndo.csv")
info <- read_csv("/Users/hailey/Documents/GitHub/G5055_Practicum_Project2/Data/processedGuate.csv")
# information: goal, target, indicator
att2 <- info[3:5] %>%
unique() %>%
filter(Indicator %in% colnames(m))
# add all the attributes to the vertex----
vertex_attr(g2, index = att2$Indicator) <- att2  #### Error in as.igraph.vs(graph, index) : Invalid vertex names
V(g2)$name <- V(g2)$Indicator
# inspect the vertexes(nodes) in the network----
vertex_attr(g2)
# width and sign of ties----
E(g2)$coefficient <- el_weighted$value
E(g2)$weight <- abs(E(g2)$coefficient)
E(g2)$sign <- ifelse(E(g2)$weight > 0, "positive",
ifelse(E(g2)$weight < 0, "negative",
ifelse(E(g2)$weight == 0, 0, NA)))
E(g2)$color <- ifelse(E(g2)$coefficient > 0, "green",
ifelse(E(g2)$coefficient < 0, "red",
ifelse(E(g2)$coefficient == 0, 0, NA)))
edge_attr(g2)
# calculate network variables: degree and several kinds of centrality score----
netatt2 <- data.frame(Indicator = V(g2)$Indicator,
degree = igraph::degree(g2), # number of neighbors # numerically equal to degree centrality # here meaningless
strength = strength(g2) # sum of the edge weights of the adjacent edges for each vertex # weight here should be absolute value # somehow it's giving all NAs
# btwn = betweenness(g2, directed = F), # betweenness centrality # DON'T RUN IT!!! r session aborts
# close = closeness(g, mode = c("all")), # closeness centrality not well-defined for disconnected graphs
# eigen = evcent(g2) # eigenvector centrality # all very high, not much help
)
V(g2)$degree <- netatt2$degree
# merge the network attributes with attributes from other data source----
att2 <- merge(att2, netatt2, by='Indicator')
# rename for later analysis with text network----
# cmatrix_d <- matrix_d
cm <- m
catt <- att2
cg <- g2
hex <- read_csv("/Users/hailey/Documents/GitHub/G5055_Practicum_Project2/Visualizations/goal_hexcodes.csv")
# df <- ggnetwork(cg,layout = with_kk())
# df <- ggnetwork(cg, layout = layout_in_circle(cg))
df <- ggnetwork(cg,layout = layout_nicely(cg))
ggplot(df, aes(x, y, xend = xend, yend = yend)) +
geom_edges(alpha = 0.2, curvature = 0.2, color="seashell3") + # aes(color = color) color="seashell3"
geom_nodes(aes(colour = as.factor(Goal), size = degree), alpha = 0.8) +
scale_color_manual(values = hex$hexcode) +
# geom_nodetext_repel(aes(label = Goal),size = 2) +
# geom_nodetext(aes(label = Target),size = 2) +
# geom_nodetext(aes(label = Indicator),size = 2) +
# geom_nodetext(aes(label = Indicator), size = 2, color = "white") +
theme_blank()
library(ggplot2)
# load data and keep all the node pairs statistically significantly related----
setwd("/Users/hailey/Documents/GitHub/G5055_Practicum_Project2/Data/PCA_results")
# d <- read_csv("indo_coefficients.csv")
# p <- read_csv("Indonesia_scaled_correlation_among_indicators_indicator_model_pval.csv") %>% rename(Var1 = X, Var2 = Y, p = `p-unc`)
d <- read_csv("gua_coefficients.csv")
p <- read_csv("Guatemala_scaled_correlation_among_indicators_indicator_model_pval.csv") %>% rename(Var1 = X, Var2 = Y, p = `p-unc`)
d2 <- merge(d, p, by = c("Var1", "Var2"))
# change the data format to matrix, to build weighted network
el_weighted <- d2 %>%
filter(Var1 != Var2) %>%
# filter(value >= 0.5 | value <= -0.5) %>%
filter(p <= 0.05) %>%
select(Var1, Var2, value) %>%
arrange(abs(value))
library(igraph)
g2 <- graph.data.frame(el_weighted, directed = FALSE)
m <- get.adjacency(g2, sparse = FALSE, attr='value')
# repeat for the weighted network g2----
# some attributes----
# info <- read_csv("/Users/hailey/Documents/GitHub/G5055_Practicum_Project2/Data/processedIndo.csv")
info <- read_csv("/Users/hailey/Documents/GitHub/G5055_Practicum_Project2/Data/processedGuate.csv")
# information: goal, target, indicator
att2 <- info[3:5] %>%
unique() %>%
filter(Indicator %in% colnames(m))
# add all the attributes to the vertex----
vertex_attr(g2, index = att2$Indicator) <- att2  #### Error in as.igraph.vs(graph, index) : Invalid vertex names
V(g2)$name <- V(g2)$Indicator
# inspect the vertexes(nodes) in the network----
vertex_attr(g2)
# width and sign of ties----
E(g2)$coefficient <- el_weighted$value
E(g2)$weight <- abs(E(g2)$coefficient)
E(g2)$sign <- ifelse(E(g2)$weight > 0, "positive",
ifelse(E(g2)$weight < 0, "negative",
ifelse(E(g2)$weight == 0, 0, NA)))
E(g2)$color <- ifelse(E(g2)$coefficient > 0, "green",
ifelse(E(g2)$coefficient < 0, "red",
ifelse(E(g2)$coefficient == 0, 0, NA)))
edge_attr(g2)
# calculate network variables: degree and several kinds of centrality score----
netatt2 <- data.frame(Indicator = V(g2)$Indicator,
degree = igraph::degree(g2), # number of neighbors # numerically equal to degree centrality # here meaningless
strength = strength(g2) # sum of the edge weights of the adjacent edges for each vertex # weight here should be absolute value # somehow it's giving all NAs
# btwn = betweenness(g2, directed = F), # betweenness centrality # DON'T RUN IT!!! r session aborts
# close = closeness(g, mode = c("all")), # closeness centrality not well-defined for disconnected graphs
# eigen = evcent(g2) # eigenvector centrality # all very high, not much help
)
V(g2)$degree <- netatt2$degree
# merge the network attributes with attributes from other data source----
att2 <- merge(att2, netatt2, by='Indicator')
# rename for later analysis with text network----
# cmatrix_d <- matrix_d
cm <- m
catt <- att2
cg <- g2
hex <- read_csv("/Users/hailey/Documents/GitHub/G5055_Practicum_Project2/Visualizations/goal_hexcodes.csv")
# df <- ggnetwork(cg,layout = with_kk())
# df <- ggnetwork(cg, layout = layout_in_circle(cg))
df <- ggnetwork(cg,layout = layout_nicely(cg))
library(ggnetwork)
hex <- read_csv("/Users/hailey/Documents/GitHub/G5055_Practicum_Project2/Visualizations/goal_hexcodes.csv")
# df <- ggnetwork(cg,layout = with_kk())
# df <- ggnetwork(cg, layout = layout_in_circle(cg))
df <- ggnetwork(cg,layout = layout_nicely(cg))
ggplot(df, aes(x, y, xend = xend, yend = yend)) +
geom_edges(alpha = 0.2, curvature = 0.2, color="seashell3") + # aes(color = color) color="seashell3"
geom_nodes(aes(colour = as.factor(Goal), size = degree), alpha = 0.8) +
scale_color_manual(values = hex$hexcode) +
# geom_nodetext_repel(aes(label = Goal),size = 2) +
# geom_nodetext(aes(label = Target),size = 2) +
# geom_nodetext(aes(label = Indicator),size = 2) +
# geom_nodetext(aes(label = Indicator), size = 2, color = "white") +
theme_blank()
cm <- round(cm, 2)

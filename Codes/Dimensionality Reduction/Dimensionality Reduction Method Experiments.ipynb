{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e41ff830",
   "metadata": {},
   "source": [
    "# Dimentionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f73e01d",
   "metadata": {},
   "source": [
    "## Some background info:\n",
    "\n",
    "1. Network on the **indicator level**\n",
    "\n",
    "2. **Why** aren we doing dimentionality reduction:   \n",
    "- Since we've decided to use the correlation coefficients to form weighted ties, the nature of network analysis requires us to have only one variable for each node, that is, select one measure to represent each indicator. Given that there are multiple measures under each indicator, we have to find a way to pick one representative variable for each target. That is, to reduce the dimention to 1.\n",
    "\n",
    "3. Time Range: 2012 - 2021\n",
    "\n",
    "4. A major **problem**: **many missing values, sparse data set, thus possibly inaccurate PCA results**\n",
    "- 2 **solutions**:\n",
    "    - 1) impute data before composite, and then feed the imputed data into models like PCA, truncated SVD, etc.\n",
    "    (imputation details: fit a linear\n",
    "    - ~~2) use models that in some way interpolate missing values by itself, e.g., PPCA~~\n",
    "    (It turns out PPCA also won't take our original data. It won't take any singular matrix（rank < n, that is, all values missing for some year, e.g., 2021). Still need to impute data before using ppca.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab6a7be",
   "metadata": {},
   "source": [
    "### Missing value imputation: \n",
    "1. the reason of missing: Missing at Random (MAR)\n",
    "\n",
    "2. Why we choose Linear Interpolation:\n",
    "What we want to do: Imputation  ->     \n",
    "What problem: Time Series Problems  ->      \n",
    "Type of data: Data with trend & without seasonality  ->        \n",
    "Method: **Linear Interpolation**       \n",
    "(reference: https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4)\n",
    "\n",
    "3. imputed data\n",
    "in this directory: https://github.com/PeishanLi/G5055_Practicum_Project2/tree/main/Data/Data_preprocessed_for_PCA/Filtered_indicators_with_eligible_measurements_missing_data/Indonesia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56efd765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48086e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use indicator 3.2.1(imputed) as example(my random choice)\n",
    "# # data folder paths\n",
    "# # original data directory （no imputation, some missing values)\n",
    "# p1 = \"/Users/hailey/Documents/GitHub/G5055_Practicum_Project2/Data/Data_preprocessed_for_PCA/Filtered_indicators_with_eligible_measurements_missing_data/Indonesia\"\n",
    "# # imputed data directory\n",
    "# p2 = \"/Users/hailey/Documents/GitHub/G5055_Practicum_Project2/Data/Data_preprocessed_for_PCA/Indicators_with_imputation/Indonesia\"\n",
    "\n",
    "# in a more general way\n",
    "indicator = \"3.2.1\"\n",
    "country = \"Indonesia\"\n",
    "original_prefix = \"../../Data/Data_preprocessed_for_PCA/Filtered_indicators_with_eligible_measurements_missing_data/\"\n",
    "imputed_prefix = \"../../Data/Data_preprocessed_for_PCA/Indicators_with_imputation/\"\n",
    "original_filepath = f\"{original_prefix}{country}/Indicator{indicator}.csv\"\n",
    "imputed_filepath = f\"{imputed_prefix}{country}/Indicator{indicator}.csv\"\n",
    "# original_filepath\n",
    "# tp = \"../../Data/Data_preprocessed_for_PCA/Filtered_indicators_with_eligible_measurements_missing_data/Indonesia/Indicator3.2.1.csv\"\n",
    "# original_filepath == tp # True\n",
    "# imputed_filepath\n",
    "# truepath = \"../../Data/Data_preprocessed_for_PCA/Indicators_with_imputation/Indonesia/Indicator3.2.1.csv\"\n",
    "# imputed_filepath == truepath # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ef31397",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_d = pd.read_csv(original_filepath, index_col = \"Year\")\n",
    "imputed_d = pd.read_csv(imputed_filepath, index_col = \"Year\")                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e484254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SH_DYN_IMRTN</th>\n",
       "      <th>SH_DYN_MORT</th>\n",
       "      <th>SH_DYN_IMRT</th>\n",
       "      <th>SH_DYN_MORTN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012.0</th>\n",
       "      <td>130247.0</td>\n",
       "      <td>31.3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>156767.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013.0</th>\n",
       "      <td>125256.0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>25.1</td>\n",
       "      <td>150331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014.0</th>\n",
       "      <td>120213.0</td>\n",
       "      <td>28.9</td>\n",
       "      <td>24.2</td>\n",
       "      <td>143968.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015.0</th>\n",
       "      <td>115140.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>23.3</td>\n",
       "      <td>137566.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016.0</th>\n",
       "      <td>110330.0</td>\n",
       "      <td>26.7</td>\n",
       "      <td>22.5</td>\n",
       "      <td>131492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017.0</th>\n",
       "      <td>105617.0</td>\n",
       "      <td>25.7</td>\n",
       "      <td>21.7</td>\n",
       "      <td>125557.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018.0</th>\n",
       "      <td>101219.0</td>\n",
       "      <td>24.8</td>\n",
       "      <td>20.9</td>\n",
       "      <td>120070.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019.0</th>\n",
       "      <td>97168.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>20.2</td>\n",
       "      <td>114994.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SH_DYN_IMRTN  SH_DYN_MORT  SH_DYN_IMRT  SH_DYN_MORTN\n",
       "Year                                                        \n",
       "2012.0      130247.0         31.3         26.0      156767.0\n",
       "2013.0      125256.0         30.1         25.1      150331.0\n",
       "2014.0      120213.0         28.9         24.2      143968.0\n",
       "2015.0      115140.0         27.8         23.3      137566.0\n",
       "2016.0      110330.0         26.7         22.5      131492.0\n",
       "2017.0      105617.0         25.7         21.7      125557.0\n",
       "2018.0      101219.0         24.8         20.9      120070.0\n",
       "2019.0       97168.0         23.9         20.2      114994.0\n",
       "2020.0           NaN          NaN          NaN           NaN\n",
       "2021.0           NaN          NaN          NaN           NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdff9c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SH_DYN_IMRTN_new</th>\n",
       "      <th>SH_DYN_MORT_new</th>\n",
       "      <th>SH_DYN_IMRT_new</th>\n",
       "      <th>SH_DYN_MORTN_new</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012.0</th>\n",
       "      <td>0</td>\n",
       "      <td>130247.000000</td>\n",
       "      <td>31.300000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>156767.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013.0</th>\n",
       "      <td>1</td>\n",
       "      <td>125256.000000</td>\n",
       "      <td>30.100000</td>\n",
       "      <td>25.100000</td>\n",
       "      <td>150331.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014.0</th>\n",
       "      <td>2</td>\n",
       "      <td>120213.000000</td>\n",
       "      <td>28.900000</td>\n",
       "      <td>24.200000</td>\n",
       "      <td>143968.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015.0</th>\n",
       "      <td>3</td>\n",
       "      <td>115140.000000</td>\n",
       "      <td>27.800000</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>137566.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016.0</th>\n",
       "      <td>4</td>\n",
       "      <td>110330.000000</td>\n",
       "      <td>26.700000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>131492.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017.0</th>\n",
       "      <td>5</td>\n",
       "      <td>105617.000000</td>\n",
       "      <td>25.700000</td>\n",
       "      <td>21.700000</td>\n",
       "      <td>125557.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018.0</th>\n",
       "      <td>6</td>\n",
       "      <td>101219.000000</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>120070.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019.0</th>\n",
       "      <td>7</td>\n",
       "      <td>97168.000000</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>114994.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020.0</th>\n",
       "      <td>8</td>\n",
       "      <td>91702.178571</td>\n",
       "      <td>22.632143</td>\n",
       "      <td>19.242857</td>\n",
       "      <td>108038.321429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021.0</th>\n",
       "      <td>9</td>\n",
       "      <td>86936.273810</td>\n",
       "      <td>21.572619</td>\n",
       "      <td>18.410714</td>\n",
       "      <td>102026.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  SH_DYN_IMRTN_new  SH_DYN_MORT_new  SH_DYN_IMRT_new  \\\n",
       "Year                                                                     \n",
       "2012.0           0     130247.000000        31.300000        26.000000   \n",
       "2013.0           1     125256.000000        30.100000        25.100000   \n",
       "2014.0           2     120213.000000        28.900000        24.200000   \n",
       "2015.0           3     115140.000000        27.800000        23.300000   \n",
       "2016.0           4     110330.000000        26.700000        22.500000   \n",
       "2017.0           5     105617.000000        25.700000        21.700000   \n",
       "2018.0           6     101219.000000        24.800000        20.900000   \n",
       "2019.0           7      97168.000000        23.900000        20.200000   \n",
       "2020.0           8      91702.178571        22.632143        19.242857   \n",
       "2021.0           9      86936.273810        21.572619        18.410714   \n",
       "\n",
       "        SH_DYN_MORTN_new  \n",
       "Year                      \n",
       "2012.0     156767.000000  \n",
       "2013.0     150331.000000  \n",
       "2014.0     143968.000000  \n",
       "2015.0     137566.000000  \n",
       "2016.0     131492.000000  \n",
       "2017.0     125557.000000  \n",
       "2018.0     120070.000000  \n",
       "2019.0     114994.000000  \n",
       "2020.0     108038.321429  \n",
       "2021.0     102026.142857  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f13f261c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the column \"Year\", transform to n-dimentional np array (n is the number of measures)\n",
    "imputed_d = imputed_d.drop([\"Unnamed: 0\"], axis = 1)\n",
    "\n",
    "imputed_d.shape # 10 records of 4 features -- 10 years, 4 measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fcbe832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "X = pd.DataFrame(scale(imputed_d), index=imputed_d.index, columns=imputed_d.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ecad85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SH_DYN_IMRTN_new</th>\n",
       "      <th>SH_DYN_MORT_new</th>\n",
       "      <th>SH_DYN_IMRT_new</th>\n",
       "      <th>SH_DYN_MORTN_new</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012.0</th>\n",
       "      <td>1.596693</td>\n",
       "      <td>1.628351</td>\n",
       "      <td>1.607899</td>\n",
       "      <td>1.602647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013.0</th>\n",
       "      <td>1.232211</td>\n",
       "      <td>1.234357</td>\n",
       "      <td>1.231503</td>\n",
       "      <td>1.230090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014.0</th>\n",
       "      <td>0.863931</td>\n",
       "      <td>0.840364</td>\n",
       "      <td>0.855107</td>\n",
       "      <td>0.861758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015.0</th>\n",
       "      <td>0.493461</td>\n",
       "      <td>0.479203</td>\n",
       "      <td>0.478710</td>\n",
       "      <td>0.491169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016.0</th>\n",
       "      <td>0.142197</td>\n",
       "      <td>0.118042</td>\n",
       "      <td>0.144136</td>\n",
       "      <td>0.139567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017.0</th>\n",
       "      <td>-0.201984</td>\n",
       "      <td>-0.210286</td>\n",
       "      <td>-0.190439</td>\n",
       "      <td>-0.203989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018.0</th>\n",
       "      <td>-0.523161</td>\n",
       "      <td>-0.505782</td>\n",
       "      <td>-0.525013</td>\n",
       "      <td>-0.521611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019.0</th>\n",
       "      <td>-0.818997</td>\n",
       "      <td>-0.801277</td>\n",
       "      <td>-0.817766</td>\n",
       "      <td>-0.815443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020.0</th>\n",
       "      <td>-1.218154</td>\n",
       "      <td>-1.217550</td>\n",
       "      <td>-1.218060</td>\n",
       "      <td>-1.218082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021.0</th>\n",
       "      <td>-1.566198</td>\n",
       "      <td>-1.565422</td>\n",
       "      <td>-1.566077</td>\n",
       "      <td>-1.566106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SH_DYN_IMRTN_new  SH_DYN_MORT_new  SH_DYN_IMRT_new  SH_DYN_MORTN_new\n",
       "Year                                                                        \n",
       "2012.0          1.596693         1.628351         1.607899          1.602647\n",
       "2013.0          1.232211         1.234357         1.231503          1.230090\n",
       "2014.0          0.863931         0.840364         0.855107          0.861758\n",
       "2015.0          0.493461         0.479203         0.478710          0.491169\n",
       "2016.0          0.142197         0.118042         0.144136          0.139567\n",
       "2017.0         -0.201984        -0.210286        -0.190439         -0.203989\n",
       "2018.0         -0.523161        -0.505782        -0.525013         -0.521611\n",
       "2019.0         -0.818997        -0.801277        -0.817766         -0.815443\n",
       "2020.0         -1.218154        -1.217550        -1.218060         -1.218082\n",
       "2021.0         -1.566198        -1.565422        -1.566077         -1.566106"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fe82ed",
   "metadata": {},
   "source": [
    "## 1. Principal Components Analysis\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "\n",
    "Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space. The input data is centered but not scaled for each feature before applying the SVD.\n",
    "\n",
    "It uses the LAPACK implementation of the full SVD or a randomized truncated SVD by the method of Halko et al. 2009, depending on the shape of the input data and the number of components to extract.\n",
    "\n",
    "It can also use the scipy.sparse.linalg ARPACK implementation of the truncated SVD.\n",
    "\n",
    "Notice that this class **does not support sparse input**. See TruncatedSVD for an alternative with sparse data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9b8c24",
   "metadata": {},
   "source": [
    "> The model description indicates that it's not a good option for our original dataset (sparse, many missing values)\n",
    "\n",
    "> Actually, it retures error when dealing with NAs -- ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
    "\n",
    "> Here I'll try PCA on the imputed data to see whether it works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7afa6a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# PCA(n_components=None, *, copy=True, whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto', random_state=None)\n",
    "pca = PCA(random_state=2231).fit(X) # n_components is not set, all components are kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fc842c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SH_DYN_IMRTN_new</th>\n",
       "      <td>0.500004</td>\n",
       "      <td>-0.415259</td>\n",
       "      <td>-0.398548</td>\n",
       "      <td>0.647082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SH_DYN_MORT_new</th>\n",
       "      <td>0.499980</td>\n",
       "      <td>0.854745</td>\n",
       "      <td>-0.088589</td>\n",
       "      <td>0.107624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SH_DYN_IMRT_new</th>\n",
       "      <td>0.500006</td>\n",
       "      <td>-0.205289</td>\n",
       "      <td>0.841338</td>\n",
       "      <td>0.000094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SH_DYN_MORTN_new</th>\n",
       "      <td>0.500010</td>\n",
       "      <td>-0.234152</td>\n",
       "      <td>-0.354205</td>\n",
       "      <td>-0.754786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        V1        V2        V3        V4\n",
       "SH_DYN_IMRTN_new  0.500004 -0.415259 -0.398548  0.647082\n",
       "SH_DYN_MORT_new   0.499980  0.854745 -0.088589  0.107624\n",
       "SH_DYN_IMRT_new   0.500006 -0.205289  0.841338  0.000094\n",
       "SH_DYN_MORTN_new  0.500010 -0.234152 -0.354205 -0.754786"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The loading vectors\n",
    "pca_loadings = pd.DataFrame(pca.components_.T, index=X.columns, columns=['V1', 'V2', 'V3', 'V4'])\n",
    "pca_loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a49fb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the PCA model and transform X to get the principal components\n",
    "X_plot = pd.DataFrame(pca.fit_transform(X), columns=['PC1', 'PC2', 'PC3', 'PC4'], index=X.index)\n",
    "X_plot \n",
    "# X_plot[\"PC1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c578d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Float64Index([2012.0, 2013.0, 2014.0, 2015.0, 2016.0, 2017.0, 2018.0, 2019.0,\n",
       "              2020.0, 2021.0],\n",
       "             dtype='float64', name='Year')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_plot.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6e041d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.44420220e+00, 2.06865128e-04, 3.45797949e-05, 8.03433096e-07])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9f5e7414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.99945494e-01, 4.65446538e-05, 7.78045385e-06, 1.80772446e-07])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a21adbf",
   "metadata": {},
   "source": [
    "> This is really great result! The first principal component explains 99.99% of the total variance, which means it can be a nearly perfect representative or the measures under this indicator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ab6116",
   "metadata": {},
   "source": [
    "## 2. TruncatedSVD\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html#sklearn.decomposition.TruncatedSVD\n",
    "\n",
    "Dimensionality reduction using truncated SVD (aka LSA).\n",
    "\n",
    "This transformer performs linear dimensionality reduction by means of truncated singular value decomposition (SVD). Contrary to PCA, this estimator **does not center the data before computing the singular value decomposition**. This means it can **work with sparse matrices efficiently**.\n",
    "\n",
    "In particular, truncated SVD works on term count/tf-idf matrices as returned by the vectorizers in sklearn.feature_extraction.text. In that context, it is known as latent semantic analysis (LSA).\n",
    "\n",
    "This estimator supports two algorithms: a fast randomized SVD solver, and a “naive” algorithm that uses ARPACK as an eigensolver on X * X.T or X.T * X, whichever is more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87704b73",
   "metadata": {},
   "source": [
    "~~Since it can work with sparse matrices efficiently, I'm putting in the original data~~(no it didn't work, same error as PCA when it finds NAs)\n",
    "\n",
    "Still working on imputed data. See if there's any difference between the result from PCA and Truncated SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "80f24ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "# TruncatedSVD(n_components=2, *, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)\n",
    "# n_components must be < n_features; so here I did n_components=3\n",
    "\n",
    "# Truncated SVD algorithm 1: a fast randomized SVD solver(default) \n",
    "# “randomized” for the randomized algorithm due to Halko (2009).\n",
    "\n",
    "tsvd1 = TruncatedSVD(n_components=3, algorithm='randomized', n_iter=5, random_state=2231).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "10622f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SH_DYN_IMRTN_new</th>\n",
       "      <td>0.500004</td>\n",
       "      <td>-0.415259</td>\n",
       "      <td>-0.398548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SH_DYN_MORT_new</th>\n",
       "      <td>0.499980</td>\n",
       "      <td>0.854745</td>\n",
       "      <td>-0.088589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SH_DYN_IMRT_new</th>\n",
       "      <td>0.500006</td>\n",
       "      <td>-0.205289</td>\n",
       "      <td>0.841338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SH_DYN_MORTN_new</th>\n",
       "      <td>0.500010</td>\n",
       "      <td>-0.234152</td>\n",
       "      <td>-0.354205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        V1        V2        V3\n",
       "SH_DYN_IMRTN_new  0.500004 -0.415259 -0.398548\n",
       "SH_DYN_MORT_new   0.499980  0.854745 -0.088589\n",
       "SH_DYN_IMRT_new   0.500006 -0.205289  0.841338\n",
       "SH_DYN_MORTN_new  0.500010 -0.234152 -0.354205"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The loading vectors\n",
    "tsvd1_loadings = pd.DataFrame(tsvd1.components_.T, index=X.columns, columns=['V1', 'V2', 'V3'])\n",
    "tsvd1_loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f3a8c87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.99978198e+00, 1.86178615e-04, 3.11218154e-05])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsvd1.explained_variance_ # different from PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e154b747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.99945494e-01, 4.65446538e-05, 7.78045385e-06])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsvd1.explained_variance_ratio_ # same result as PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f5600230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012.0</th>\n",
       "      <td>3.217795</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.004509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013.0</th>\n",
       "      <td>2.464080</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>-0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014.0</th>\n",
       "      <td>1.710580</td>\n",
       "      <td>-0.017784</td>\n",
       "      <td>-0.004570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015.0</th>\n",
       "      <td>0.971272</td>\n",
       "      <td>-0.008600</td>\n",
       "      <td>-0.010337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016.0</th>\n",
       "      <td>0.271971</td>\n",
       "      <td>-0.020422</td>\n",
       "      <td>0.004702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017.0</th>\n",
       "      <td>-0.403349</td>\n",
       "      <td>-0.009006</td>\n",
       "      <td>0.011160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018.0</th>\n",
       "      <td>-1.037784</td>\n",
       "      <td>0.014848</td>\n",
       "      <td>-0.003645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019.0</th>\n",
       "      <td>-1.626741</td>\n",
       "      <td>0.014024</td>\n",
       "      <td>-0.001790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020.0</th>\n",
       "      <td>-2.435923</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021.0</th>\n",
       "      <td>-3.131901</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PC1       PC2       PC3\n",
       "Year                                \n",
       "2012.0  3.217795  0.023438  0.004509\n",
       "2013.0  2.464080  0.002533 -0.000039\n",
       "2014.0  1.710580 -0.017784 -0.004570\n",
       "2015.0  0.971272 -0.008600 -0.010337\n",
       "2016.0  0.271971 -0.020422  0.004702\n",
       "2017.0 -0.403349 -0.009006  0.011160\n",
       "2018.0 -1.037784  0.014848 -0.003645\n",
       "2019.0 -1.626741  0.014024 -0.001790\n",
       "2020.0 -2.435923  0.000424  0.000004\n",
       "2021.0 -3.131901  0.000546  0.000006"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the PCA model and transform X to get the principal components\n",
    "pd.DataFrame(tsvd1.fit_transform(X), columns=['PC1', 'PC2', 'PC3'], index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "57861215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncated SVD algorithm 2: ARPACK as an eigensolver on X * X.T or X.T * X\n",
    "# “arpack” for the ARPACK wrapper in SciPy (scipy.sparse.linalg.svds)\n",
    "tsvd2 = TruncatedSVD(n_components=3, algorithm='arpack', n_iter=5, random_state=2231).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "58d084ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SH_DYN_IMRTN_new</th>\n",
       "      <td>0.500004</td>\n",
       "      <td>-0.415259</td>\n",
       "      <td>-0.398548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SH_DYN_MORT_new</th>\n",
       "      <td>0.499980</td>\n",
       "      <td>0.854745</td>\n",
       "      <td>-0.088589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SH_DYN_IMRT_new</th>\n",
       "      <td>0.500006</td>\n",
       "      <td>-0.205289</td>\n",
       "      <td>0.841338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SH_DYN_MORTN_new</th>\n",
       "      <td>0.500010</td>\n",
       "      <td>-0.234152</td>\n",
       "      <td>-0.354205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        V1        V2        V3\n",
       "SH_DYN_IMRTN_new  0.500004 -0.415259 -0.398548\n",
       "SH_DYN_MORT_new   0.499980  0.854745 -0.088589\n",
       "SH_DYN_IMRT_new   0.500006 -0.205289  0.841338\n",
       "SH_DYN_MORTN_new  0.500010 -0.234152 -0.354205"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The loading vectors\n",
    "tsvd2_loadings = pd.DataFrame(tsvd2.components_.T, index=X.columns, columns=['V1', 'V2', 'V3'])\n",
    "tsvd2_loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "20a563d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.99978198e+00, 1.86178615e-04, 3.11218154e-05])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsvd2.explained_variance_ # different from PCA # same as tsvd1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6c69f50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.99945494e-01, 4.65446538e-05, 7.78045385e-06])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsvd2.explained_variance_ratio_ # same result as PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "384ba409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012.0</th>\n",
       "      <td>3.217795</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.004509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013.0</th>\n",
       "      <td>2.464080</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>-0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014.0</th>\n",
       "      <td>1.710580</td>\n",
       "      <td>-0.017784</td>\n",
       "      <td>-0.004570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015.0</th>\n",
       "      <td>0.971272</td>\n",
       "      <td>-0.008600</td>\n",
       "      <td>-0.010337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016.0</th>\n",
       "      <td>0.271971</td>\n",
       "      <td>-0.020422</td>\n",
       "      <td>0.004702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017.0</th>\n",
       "      <td>-0.403349</td>\n",
       "      <td>-0.009006</td>\n",
       "      <td>0.011160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018.0</th>\n",
       "      <td>-1.037784</td>\n",
       "      <td>0.014848</td>\n",
       "      <td>-0.003645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019.0</th>\n",
       "      <td>-1.626741</td>\n",
       "      <td>0.014024</td>\n",
       "      <td>-0.001790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020.0</th>\n",
       "      <td>-2.435923</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021.0</th>\n",
       "      <td>-3.131901</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PC1       PC2       PC3\n",
       "Year                                \n",
       "2012.0  3.217795  0.023438  0.004509\n",
       "2013.0  2.464080  0.002533 -0.000039\n",
       "2014.0  1.710580 -0.017784 -0.004570\n",
       "2015.0  0.971272 -0.008600 -0.010337\n",
       "2016.0  0.271971 -0.020422  0.004702\n",
       "2017.0 -0.403349 -0.009006  0.011160\n",
       "2018.0 -1.037784  0.014848 -0.003645\n",
       "2019.0 -1.626741  0.014024 -0.001790\n",
       "2020.0 -2.435923  0.000424  0.000004\n",
       "2021.0 -3.131901  0.000546  0.000006"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the PCA model and transform X to get the principal components\n",
    "pd.DataFrame(tsvd2.fit_transform(X), columns=['PC1', 'PC2', 'PC3'], index=X.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c46ba7",
   "metadata": {},
   "source": [
    "> Since with imputed data there's no difference between PCA and Truncated SVD, to make the most of Truncated SVD and tell the difference between PCA and it, we should imputed data to make it non-sigular(full range) by deleting the empty rows.\n",
    "\n",
    "> Indicator3.2.1 has no missing value except for the empty rows 2020 and 2021, so I need to try it out on another example. I chose **Indicator2.2.1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "90dcfe7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SH_STA_STNT</th>\n",
       "      <th>SH_STA_STNTN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8094.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013.0</th>\n",
       "      <td>36.4</td>\n",
       "      <td>8077.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8068.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8024.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8068.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7992.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018.0</th>\n",
       "      <td>30.8</td>\n",
       "      <td>7840.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7668.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7526.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SH_STA_STNT  SH_STA_STNTN\n",
       "Year                             \n",
       "2012.0          NaN        8094.2\n",
       "2013.0         36.4        8077.2\n",
       "2014.0          NaN        8068.6\n",
       "2015.0          NaN        8024.6\n",
       "2016.0          NaN        8068.8\n",
       "2017.0          NaN        7992.9\n",
       "2018.0         30.8        7840.4\n",
       "2019.0          NaN        7668.0\n",
       "2020.0          NaN        7526.1"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in a more general way\n",
    "indicator = \"2.2.1\"\n",
    "country = \"Indonesia\"\n",
    "original_prefix = \"../../Data/Data_preprocessed_for_PCA/Filtered_indicators_with_eligible_measurements_missing_data/\"\n",
    "imputed_prefix = \"../../Data/Data_preprocessed_for_PCA/Indicators_with_imputation/\"\n",
    "original_filepath = f\"{original_prefix}{country}/Indicator{indicator}.csv\"\n",
    "imputed_filepath = f\"{imputed_prefix}{country}/Indicator{indicator}.csv\"\n",
    "\n",
    "original_d = pd.read_csv(original_filepath, index_col = \"Year\")\n",
    "original_d.drop(original_d.index[-1], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cc5ae9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(scale(original_d), random_state=2231).fit(X) \n",
    "# # PCA does not work because of missing values:\n",
    "# # ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d247acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsvd = TruncatedSVD(n_components=3, n_iter=5, random_state=2231).fit(scale(original_d))\n",
    "# # TSVD does not work because of missing values:\n",
    "# # ValueError: Input contains NaN, infinity or a value too large for dtype('float64')."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15e0b82",
   "metadata": {},
   "source": [
    "## 3. Probabilistic Principal Components Analysis\n",
    "\n",
    "### 3.1 ~~GitHub repo: pca-magic~~ (similarly constructed as PCA, but turned out to be ill-defined and yields strange results, so in the end I chose not to use it)           \n",
    "~~https://github.com/allentran/pca-magic~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fde529d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppca import PPCA\n",
    "ppca = PPCA()\n",
    "# ppca.fit(data=X, d=4, verbose=True)\n",
    "ppca.fit(X.to_numpy(), d=4) # it won't take pd data frame, only np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f3e936fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.11105055, 1.11110227, 1.11111091, 1.11111111])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dir(ppca)\n",
    "variance_explained = ppca.var_exp\n",
    "variance_explained # ppca has no attribute like pca.explained_variance_ratio\n",
    "# stange results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87aeb0f",
   "metadata": {},
   "source": [
    "> *Can't set the number of principal component to 1 (as we need)-- LinAlgError: 0-dimensional array given. Array must be at least two-dimensional*\n",
    "> It's possible to pick the first Component as the representative variable, however, the variance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "be1eaaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(ppca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dd0e374b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5966933 ,  1.62835122,  1.60789914,  1.60264667],\n",
       "       [ 1.23221105,  1.23435745,  1.23150287,  1.23008964],\n",
       "       [ 0.86393136,  0.84036369,  0.8551066 ,  0.86175831],\n",
       "       [ 0.49346082,  0.47920274,  0.47871033,  0.49116942],\n",
       "       [ 0.14219662,  0.11804178,  0.14413587,  0.13956727],\n",
       "       [-0.20198387, -0.21028636, -0.19043859, -0.20398866],\n",
       "       [-0.52316057, -0.50578168, -0.52501305, -0.52161148],\n",
       "       [-0.81899659, -0.80127701, -0.8177657 , -0.81544297],\n",
       "       [-1.21815405, -1.21755018, -1.21806015, -1.21808234],\n",
       "       [-1.56619807, -1.56542166, -1.56607733, -1.56610587]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components = ppca.data\n",
    "components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1d77cf3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.00004289e-01,  4.15258886e-01, -3.98548301e-01,\n",
       "        -6.47081927e-01],\n",
       "       [ 4.99979557e-01, -8.54745271e-01, -8.85888637e-02,\n",
       "        -1.07624246e-01],\n",
       "       [ 5.00006158e-01,  2.05288931e-01,  8.41338391e-01,\n",
       "        -9.38217149e-05],\n",
       "       [ 5.00009996e-01,  2.34151735e-01, -3.54204710e-01,\n",
       "         7.54786057e-01]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params = ppca.C\n",
    "model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d04ab3",
   "metadata": {},
   "source": [
    "### 3.2 The tensorflow version:   \n",
    "Probabilistic principal components analysis (PCA) is a dimensionality reduction technique that analyzes data via a lower dimensional latent space (Tipping and Bishop 1999). It is often used when there are missing values in the data or for multidimensional scaling.\n",
    "https://www.tensorflow.org/probability/examples/Probabilistic_PCA\n",
    "(I've never used tensorflow, I tried but can't make it out. Anyone willing to have a try can read the codes from the link above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa78e90",
   "metadata": {},
   "source": [
    "## 4. Random Projection\n",
    "\n",
    "https://scikit-learn.org/stable/modules/random_projection.html\n",
    "- Random projection is a powerful dimensionality reduction method that is computationally more efficient tha PCA. It is commonly used in datasets that have **too many dimensions** for PCA to be directly computed.\n",
    "(We don't need to use it, since PCA works just fine.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9ece4f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn import random_projection\n",
    "# # X = np.random.rand(100, 10000)\n",
    "# transformer = random_projection.SparseRandomProjection()\n",
    "# X_new = transformer.fit_transform(X)\n",
    "# X_new.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a276ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Packages \n",
    "import pandas as pd \n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02063d9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'indonesia_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-10101070f4cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Indonesia Data including '[Units]' Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mindonesia_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'[Units]'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'indonesia_full' is not defined"
     ]
    }
   ],
   "source": [
    "# Indonesia Data including '[Units]' Data \n",
    "indonesia_full['[Units]'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ff1037c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Indicator13.1.2.csv',\n",
       " 'Indicator8.8.2.csv',\n",
       " 'Indicator17.9.1.csv',\n",
       " 'Indicator13.1.1.csv',\n",
       " 'Indicator3.b.1.csv',\n",
       " 'Indicator11.6.2.csv',\n",
       " 'Indicator10.4.1.csv',\n",
       " 'Indicator6.5.1.csv',\n",
       " 'Indicator1.a.2.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path for missing data directories - each indicator is saved as a seperate CSV \n",
    "path_g = '../../../Data/Data_preprocessed_for_PCA/Filtered_indicators_with_eligible_measurements_missing_data/Guatemala/'\n",
    "path_i = '../../../Data/Data_preprocessed_for_PCA/Filtered_indicators_with_eligible_measurements_missing_data/Indonesia/'\n",
    "\n",
    "extension = 'csv'\n",
    "\n",
    "# generate path list for guatemala\n",
    "guatemala_paths = glob.glob(path_g+'*.{}'.format(extension))\n",
    "\n",
    "# generate csv list for guatemala \n",
    "guatemala_list = []\n",
    "for string in guatemala_paths: \n",
    "    string = string.replace(path_g,'')\n",
    "    guatemala_list.append(string)\n",
    "\n",
    "\n",
    "# generate path list for indonesia \n",
    "indonesia_paths = glob.glob(path_i+'*.{}'.format(extension))\n",
    "\n",
    "# generate csv list for indonesia \n",
    "indonesia_list = []\n",
    "for string in indonesia_paths: \n",
    "    string = string.replace(path_i,'')\n",
    "    indonesia_list.append(string)\n",
    "indonesia_list[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db71abef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SG_STT_NSDSFDGVT\n",
      "columns with 1 or fewer records:  1\n",
      "31\n",
      "proportion of columns with 1 or fewer records:  0.03225806451612903\n",
      "SG_STT_NSDSFDDNR\n",
      "columns with 1 or fewer records:  2\n",
      "32\n",
      "proportion of columns with 1 or fewer records:  0.0625\n",
      "SG_STT_NSDSFDOTHR\n",
      "columns with 1 or fewer records:  3\n",
      "33\n",
      "proportion of columns with 1 or fewer records:  0.09090909090909091\n",
      "VC_DSR_HOLH\n",
      "columns with 1 or fewer records:  4\n",
      "58\n",
      "proportion of columns with 1 or fewer records:  0.06896551724137931\n",
      "VC_DSR_CDAN\n",
      "columns with 1 or fewer records:  5\n",
      "60\n",
      "proportion of columns with 1 or fewer records:  0.08333333333333333\n",
      "VC_DSR_HFDN\n",
      "columns with 1 or fewer records:  6\n",
      "61\n",
      "proportion of columns with 1 or fewer records:  0.09836065573770492\n",
      "VC_DSR_EFDN\n",
      "columns with 1 or fewer records:  7\n",
      "62\n",
      "proportion of columns with 1 or fewer records:  0.11290322580645161\n",
      "VC_DSR_CDYN\n",
      "columns with 1 or fewer records:  8\n",
      "63\n",
      "proportion of columns with 1 or fewer records:  0.12698412698412698\n",
      "VC_DSR_BSDN\n",
      "columns with 1 or fewer records:  9\n",
      "64\n",
      "proportion of columns with 1 or fewer records:  0.140625\n",
      "VC_DSR_ESDN\n",
      "columns with 1 or fewer records:  10\n",
      "65\n",
      "proportion of columns with 1 or fewer records:  0.15384615384615385\n",
      "EN_WBE_HMWTL\n",
      "columns with 1 or fewer records:  11\n",
      "76\n",
      "proportion of columns with 1 or fewer records:  0.14473684210526316\n",
      "EN_WBE_WTLN\n",
      "columns with 1 or fewer records:  12\n",
      "87\n",
      "proportion of columns with 1 or fewer records:  0.13793103448275862\n",
      "EN_WBE_WTLP\n",
      "columns with 1 or fewer records:  13\n",
      "88\n",
      "proportion of columns with 1 or fewer records:  0.14772727272727273\n",
      "VC_DSR_HOLH\n",
      "columns with 1 or fewer records:  14\n",
      "172\n",
      "proportion of columns with 1 or fewer records:  0.08139534883720931\n",
      "AG_LND_FRSTCHG\n",
      "columns with 1 or fewer records:  15\n",
      "225\n",
      "proportion of columns with 1 or fewer records:  0.06666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Indonesia Imputation Code - Linear Regression \n",
    "# Read in full dataset with series code and units - this df includes non-disaggregated indicator measures' series codes and their units \n",
    "indonesia_full = pd.read_csv('https://raw.githubusercontent.com/PeishanLi/G5055_Practicum_Project2/main/Data/Indonesia%20Data%20Without%20Disaggregation.csv')\n",
    "series_units = indonesia_full[['SeriesCode','[Units]']]\n",
    "series_units = series_units.drop_duplicates()\n",
    "\n",
    "# iteratively impute missing data - this for loop will include notes; guatemala follows the same structure (notes in this python chunk only)\n",
    "path_i_out = '../../../Data/Data_preprocessed_for_PCA/Indicators_with_imputation/Indonesia/'\n",
    "count = 0 \n",
    "count_2 = 0 \n",
    "for csv in indonesia_list: \n",
    "    df = pd.read_csv(path_i+csv)\n",
    "    for col in df.loc[:, df.columns != 'Year']:\n",
    "        count_2 = count_2 + 1\n",
    "        if (df[col].isnull().sum(axis=0) == 0):\n",
    "            df[str(col)+'_new'] = df[col]\n",
    "            df = df.drop(columns = [str(col)])\n",
    "\n",
    "        elif (df[col].notnull().sum(axis=0) > 1) & (df[col].isnull().sum(axis=0) >= 1):\n",
    "            missing_rows = df[df[col].isnull()]\n",
    "            nonmissing_rows = df[df[col].notnull()]\n",
    "            missing_years = missing_rows[['Year']]\n",
    "            \n",
    "            # Select non missing rows to train a linear regression model \n",
    "            y = nonmissing_rows[col]\n",
    "            X = nonmissing_rows[['Year']]\n",
    "            lm = LinearRegression().fit(X,y)\n",
    "            \n",
    "            # impute for missing rows based on trained model. \n",
    "            missing_rows[\"inferred_col\"] = missing_rows.apply(lambda _: '', axis=1)\n",
    "            missing_rows[\"inferred_col\"] = lm.predict(missing_years)\n",
    "            # set lower bound of 0 \n",
    "            missing_rows[\"inferred_col\"] = missing_rows[\"inferred_col\"].clip(lower=0)\n",
    "            \n",
    "            # logical upper bounds baased on unit type - 'per n' sets max at n, percent sets max at 100, etc.\n",
    "            for i in np.logspace(0,10,10):\n",
    "                if (series_units[series_units['SeriesCode']==str(col)]['[Units]']=='PER_'+str(i)+'_POP') is True: \n",
    "                    missing_rows[\"inferred_col\"] = missing_rows[\"inferred_col\"].clip(upper=i)\n",
    "            if (series_units[series_units['SeriesCode']==str(col)]['[Units]']=='PERCENT') is True:\n",
    "                missing_rows[\"inferred_col\"] = missing_rows[\"inferred_col\"].clip(upper=100)\n",
    "            elif (series_units[series_units['SeriesCode']==str(col)]['[Units]']=='SCORE') is True: \n",
    "                missing_rows[\"inferred_col\"] = missing_rows[\"inferred_col\"].clip(upper=10)\n",
    "            elif (series_units[series_units['SeriesCode']==str(col)]['[Units]']=='Ratio') is True: \n",
    "                missing_rows[\"inferred_col\"] = missing_rows[\"inferred_col\"].clip(upper=1)\n",
    "            \n",
    "            # add this imputed data into a new column, and drop original column for this new df. \n",
    "            missing_rows = missing_rows[[\"Year\",\"inferred_col\"]]\n",
    "            df = df.merge(missing_rows, on='Year', how ='left')\n",
    "            df[str(col)+'_new'] = np.where(df[col].isnull(),df[\"inferred_col\"],df[col])\n",
    "            df = df.drop(columns = [\"inferred_col\", str(col)])\n",
    "        \n",
    "        # drop columns with 1 or fewer records \n",
    "        elif df[col].notnull().sum(axis=0) <= 1:\n",
    "            print(str(col))\n",
    "            count = count + 1\n",
    "            print('columns with 1 or fewer records: ', count)\n",
    "            print(count_2)\n",
    "            print('proportion of columns with 1 or fewer records: ', count/count_2)\n",
    "            \n",
    "            df = df.drop(columns = [str(col)])\n",
    "            \n",
    "    df.to_csv(path_i_out + csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "097c7615",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count:  1\n",
      "28\n",
      "proportion of columns with 1 or fewer records:  0.03571428571428571\n",
      "count:  2\n",
      "29\n",
      "proportion of columns with 1 or fewer records:  0.06896551724137931\n",
      "count:  3\n",
      "102\n",
      "proportion of columns with 1 or fewer records:  0.029411764705882353\n",
      "count:  4\n",
      "180\n",
      "proportion of columns with 1 or fewer records:  0.022222222222222223\n",
      "count:  5\n",
      "181\n",
      "proportion of columns with 1 or fewer records:  0.027624309392265192\n"
     ]
    }
   ],
   "source": [
    "# Guatemala Imputation Code - Linear Regression \n",
    "\n",
    "guatemala_full = pd.read_csv('https://raw.githubusercontent.com/PeishanLi/G5055_Practicum_Project2/main/Data/Guatmala%20Data%20Without%20Disaggregation.csv')\n",
    "series_units = guatemala_full[['SeriesCode','[Units]']]\n",
    "series_units = series_units.drop_duplicates()\n",
    "\n",
    "path_g_out = '../../../Data/Data_preprocessed_for_PCA/Indicators_with_imputation/Guatemala/'\n",
    "count = 0 \n",
    "count_2 = 0 \n",
    "\n",
    "for csv in guatemala_list: \n",
    "    df = pd.read_csv(path_g+csv)\n",
    "    for col in df.loc[:, df.columns != 'Year']:\n",
    "        count_2 = count_2 + 1\n",
    "        if (df[col].isnull().sum(axis=0) == 0):\n",
    "            df[str(col)+'_new'] = df[col]\n",
    "            df = df.drop(columns = [str(col)])\n",
    "        elif (df[col].notnull().sum(axis=0) > 1) & (df[col].isnull().sum(axis=0) >= 1):\n",
    "            missing_rows = df[df[col].isnull()]\n",
    "            nonmissing_rows = df[df[col].notnull()]\n",
    "            missing_years = missing_rows[['Year']]\n",
    "            y = nonmissing_rows[col]\n",
    "            X = nonmissing_rows[['Year']]\n",
    "            lm = LinearRegression().fit(X,y)\n",
    "            missing_rows[\"inferred_col\"] = missing_rows.apply(lambda _: '', axis=1)\n",
    "            missing_rows[\"inferred_col\"] = lm.predict(missing_years)\n",
    "            missing_rows[\"inferred_col\"] = missing_rows[\"inferred_col\"].clip(lower=0)\n",
    "            for i in np.logspace(0,10,10):\n",
    "                if (series_units[series_units['SeriesCode']==str(col)]['[Units]']=='PER_'+str(i)+'_POP') is True: \n",
    "                    missing_rows[\"inferred_col\"] = missing_rows[\"inferred_col\"].clip(upper=i)\n",
    "            if (series_units[series_units['SeriesCode']==str(col)]['[Units]']=='PERCENT') is True:\n",
    "                missing_rows[\"inferred_col\"] = missing_rows[\"inferred_col\"].clip(upper=100)\n",
    "            elif (series_units[series_units['SeriesCode']==str(col)]['[Units]']=='SCORE') is True: \n",
    "                missing_rows[\"inferred_col\"] = missing_rows[\"inferred_col\"].clip(upper=10)\n",
    "            elif (series_units[series_units['SeriesCode']==str(col)]['[Units]']=='Ratio') is True: \n",
    "                missing_rows[\"inferred_col\"] = missing_rows[\"inferred_col\"].clip(upper=1)\n",
    "            missing_rows = missing_rows[[\"Year\",\"inferred_col\"]]\n",
    "            df = df.merge(missing_rows, on='Year', how ='left')\n",
    "            df[str(col)+'_new'] = np.where(df[col].isnull(),df[\"inferred_col\"],df[col])\n",
    "            df = df.drop(columns = [\"inferred_col\", str(col)])\n",
    "        elif df[col].notnull().sum(axis=0) <= 1:\n",
    "            count = count + 1\n",
    "            print('count: ', count)\n",
    "            print(count_2)\n",
    "            print('proportion of columns with 1 or fewer records: ', count/count_2)\n",
    "            df = df.drop(columns = [str(col)])\n",
    "    df.to_csv(path_g_out + csv)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d47fb996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03875968992248062"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20/(181+335)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

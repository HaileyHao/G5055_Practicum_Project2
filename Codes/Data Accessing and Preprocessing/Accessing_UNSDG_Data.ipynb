{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ey-so1V7qTHg"
   },
   "source": [
    "# Import UNSDG Data from database 1 using API\n",
    "\n",
    "\n",
    "*https://unstats.un.org/sdgs/unsdg*\n",
    "\n",
    "\n",
    "P.S. Using SDG Analytics we could check the data availability for countries we're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "4rSBJKf3pYbU"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from pprint import pprint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UN uses M49 codes as 'geocode'. We import a converter from coco for use in our function. \n",
    "#!pip install country-converter\n",
    "import country_converter as coco \n",
    "coco.convert(names='China', to='UNcode')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_indicator_data(country, outpath): \n",
    "    geo_area_code = coco.convert(names=str(country), to='UNcode')\n",
    "    \n",
    "    headers={\n",
    "    'Content-Type': 'application/x-www-form-urlencoded',\n",
    "    'Accept': 'application/octet-stream',\n",
    "    }\n",
    "    \n",
    "    data=[\n",
    "      ('goal', '1'),\n",
    "      ('goal', '2'),\n",
    "      ('goal', '3'),\n",
    "      ('goal', '4'),\n",
    "      ('goal', '5'),\n",
    "      ('goal', '6'),\n",
    "      ('goal', '7'),\n",
    "      ('goal', '8'),\n",
    "      ('goal', '9'),\n",
    "      ('goal', '10'),\n",
    "      ('goal', '11'),\n",
    "      ('goal', '12'),\n",
    "      ('goal', '13'),\n",
    "      ('goal', '14'),\n",
    "      ('goal', '15'),\n",
    "      ('goal', '16'),\n",
    "      ('goal', '17'),\n",
    "      ('areaCodes', str(geo_area_code)),\n",
    "      ('timePeriodStart', '2012'),\n",
    "      ('timePeriodEnd', '2022'),\n",
    "    ]\n",
    "    \n",
    "    tocsv=requests.post('https://unstats.un.org/SDGAPI/v1/sdg/Goal/DataCSV', headers=headers, data=data)\n",
    "    country_content=tocsv.content\n",
    "    csv_name = outpath + country + \".csv\"\n",
    "\n",
    "    csv_file = open(csv_name, 'wb')\n",
    "    csv_file.write(country_content)\n",
    "    csv_file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df): \n",
    "        \n",
    "    df_copy  = df.copy()\n",
    "\n",
    "    # If a column with unique identifying info has nothing, we then will have blanks for those fields - otherwise concatenating the text will be NanNan etc. \n",
    "    df_copy = df_copy.dropna(axis = 1, how = 'all')\n",
    "\n",
    "    # Concatenated Column with a number of identifiers \n",
    "    df_copy['UniqueID'] = df_copy[['SeriesCode','[Sex]',\\\n",
    "                                   '[Deviation Level]', '[Mountain Elevation]',\\\n",
    "                                   '[Parliamentary committees]', '[Mode of transportation]',\\\n",
    "                                   '[Type of speed]', '[Policy instruments]', '[Type of skill]',\\\n",
    "                                   '[Education level]', '[Location]', '[Food Waste Sector]',\\\n",
    "                                   '[Freq]', '[Type of product]', '[Observation Status]',\\\n",
    "                                   '[Type of occupation]','[Name of non-communicable disease]', '[Level/Status]',\\\n",
    "                                   '[Age]', '[Disability status]','[Frequency of Chlorophyll-a concentration]',\\\n",
    "                                   '[Activity]', '[Level of requirement]', '[Quantile]',\\\n",
    "                                   '[IHR Capacity]','[Name of international institution]'\\\n",
    "                                  ]].astype(str).apply(lambda x: ' '.join(x), axis=1)\n",
    "    duplicates = df_copy[df_copy.duplicated(subset=['UniqueID','Goal', 'Target', 'Indicator',\\\n",
    "                                      'SeriesCode', 'SeriesDescription','Source','TimePeriod'])]\n",
    "    duplicates # if you print duplicates (outside of this function) you will find a small number of duplicate columns; \n",
    "    # however when I looked at them, the values were largely consistent - the only differing column I could find was Value. \n",
    "    # Let me know if you think this should be done differently. \n",
    "    \n",
    "    # For the time being I will remove columns that are duplicates across all columns (less that of 'Values')\n",
    "    df_copy = df_copy[['UniqueID','Source','Goal', 'Target', 'Indicator', 'SeriesCode', 'SeriesDescription','[Units]','[Nature]',\n",
    "       'GeoAreaCode', 'GeoAreaName', 'Time_Detail', 'Value','[Reporting Type]','TimePeriod']].drop_duplicates(subset = ['UniqueID','Source','Goal', 'Target', 'Indicator', 'SeriesCode', 'SeriesDescription','[Units]','[Nature]',\n",
    "       'GeoAreaCode', 'GeoAreaName', 'Time_Detail','[Reporting Type]','TimePeriod'])\n",
    "    # Pivot on year. \n",
    "    df_copy_pivot = df_copy.pivot(index=['UniqueID','Goal', 'Target', 'Indicator',\\\n",
    "                                      'SeriesCode', 'SeriesDescription','Source'], columns=['TimePeriod'],values='Value').reset_index()\n",
    "    df_copy_pivot.to_csv('../../Data/Time_Pivot_Data/'+str(df.name)+'_indicators_time.csv')\n",
    "    return df_copy_pivot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRUn1ENktx-S"
   },
   "source": [
    "Return all data for interesting countries  to a csv \n",
    "\n",
    "*Convert curl to python commands https://curl.trillworks.com/#python*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = '../../Data/Raw_Data/'\n",
    "obtain_indicator_data('Indonesia',outpath)\n",
    "obtain_indicator_data('Guatemala',outpath)\n",
    "#obtain_indicator_data('Barbados')\n",
    "#obtain_indicator_data('Malawi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-237-4305fa4efec1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mIndonesia\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://github.com/PeishanLi/G5055_Practicum_Project2/blob/main/Data/Raw_Data/Indonesia.csv?raw=true'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndonesia\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mIndonesia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-236-481f86dc0255>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     31\u001b[0m     df_copy_pivot = df_copy.pivot(index=['UniqueID','Goal', 'Target', 'Indicator',\\\n\u001b[1;32m     32\u001b[0m                                       'SeriesCode', 'SeriesDescription','Source'], columns=['TimePeriod'],values='Value').reset_index()\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mdf_copy_pivot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../Data/Time_Pivot_Data/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_indicators_time.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf_copy_pivot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5461\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5462\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "Indonesia = pd.read_csv('https://github.com/PeishanLi/G5055_Practicum_Project2/blob/main/Data/Raw_Data/Indonesia.csv?raw=true')\n",
    "preprocess(Indonesia)\n",
    "\n",
    "Indonesia"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Accessing_UNSDG_Data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

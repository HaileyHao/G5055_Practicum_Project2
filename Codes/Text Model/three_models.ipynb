{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hannahz/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd() \n",
    "os.chdir('/Users/hannahz/Desktop/G5055_Practicum_Project2/Data/Text_Model_Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('definition_filled.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean the definition column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove \\n\n",
    "df['definition'] = df['definition'].replace(r'\\n','', regex=True) \n",
    "#remove multiple whitespace\n",
    "df['definition'] = df['definition'].replace('\\s+', ' ', regex=True)\n",
    "#remove white space in the beginning and end\n",
    "df['definition'] = df['definition'].str.strip()\n",
    "stop_words_l=stopwords.words('english')\n",
    "# removing special characters and stop words from the text and lower case\n",
    "df['definition']=df['definition'].apply(lambda x: \" \".join(re.sub(r'[^a-zA-Z0-9$]','',w).lower() for w in x.split() if re.sub(r'[^a-zA-Z0-9$]',' ',w).lower() not in stop_words_l) )\n",
    "\n",
    "#remove white space \n",
    "df['definition'] = df['definition'].replace('\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the goal index out of index eg 1, 2\n",
    "goal_num = df['Index']\n",
    "df['goal_num'] = [re.findall(r'^(\\d+).', goal)[0] for goal in goal_num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use tf-idf to do word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "tfidfvectoriser=TfidfVectorizer()\n",
    "tfidfvectoriser.fit(df['definition'])\n",
    "tfidf_vectors=tfidfvectoriser.transform(df['definition'])\n",
    "\n",
    "#calculate similarity based on the vectors\n",
    "pairwise_similarities=cosine_similarity(tfidf_vectors.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert similarity to a dataframeÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similardocs_one(doc_id,similarity_matrix):\n",
    "    #find the index for the doc_id\n",
    "    index = df.iloc[doc_id]['Index']\n",
    "    #initiated related index\n",
    "    related_index = []\n",
    "    similar_score = similarity_matrix[doc_id]\n",
    "    score_sort = np.sort(similar_score)[::-1]\n",
    "    #find related doc_id, sort from most similar to least similar \n",
    "    similar_ix=np.argsort(similarity_matrix[doc_id])[::-1] # sort doc_id from most similar to least \n",
    "    #find corresponded index for doc_id\n",
    "    for ix in similar_ix:\n",
    "        if ix==doc_id:\n",
    "            continue\n",
    "        related_index.append(df.iloc[ix][\"Index\"])\n",
    "    #create a dataframe of\n",
    "    relation_df = pd.DataFrame({'indicator': np.repeat(index, len(related_index)),\n",
    "                                'related_indicator': related_index,\n",
    "                                'similarity_score': score_sort[1:]})\n",
    "    return relation_df\n",
    "\n",
    "list_of_dataframes = [similardocs_one(x,pairwise_similarities) for x in range(len(df['Index']))]\n",
    "outcome_tf_idf = pd.concat(list_of_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_tf_idf = outcome_tf_idf.rename(columns = {'similarity_score':'similarity_score_tf_idf','related_indicator':'related_indicator_tf_idf'})\n",
    "outcome_tf_idf_new = outcome_tf_idf.groupby('indicator').head().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indicator</th>\n",
       "      <th>related_indicator_tf_idf</th>\n",
       "      <th>similarity_score_tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1.1</td>\n",
       "      <td>1.2.1</td>\n",
       "      <td>0.414994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1.1</td>\n",
       "      <td>10.2.1</td>\n",
       "      <td>0.193975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.1.1</td>\n",
       "      <td>10.7.4</td>\n",
       "      <td>0.158748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1.1</td>\n",
       "      <td>16.8.1</td>\n",
       "      <td>0.155508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1.1</td>\n",
       "      <td>16.b.1</td>\n",
       "      <td>0.152244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  indicator related_indicator_tf_idf  similarity_score_tf_idf\n",
       "0     1.1.1                    1.2.1                 0.414994\n",
       "1     1.1.1                   10.2.1                 0.193975\n",
       "2     1.1.1                   10.7.4                 0.158748\n",
       "3     1.1.1                   16.8.1                 0.155508\n",
       "4     1.1.1                   16.b.1                 0.152244"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_tf_idf_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict the belonged goal using word embedding result to evaluate the accuracy of word embedding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lidan/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lidan/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.579047619047619, 0.44, 0.4321818181818181, None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the belonged goal by the embedded definition, to check the accuracy of embedding\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_vectors.toarray(), df['goal_num'], test_size=0.2, random_state=42)\n",
    "clf = RandomForestClassifier(random_state=123)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "precision_recall_fscore_support(y_test, y_pred, average='weighted')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use bert to do word embeddings and calculate the similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "document_embeddings = sbert_model.encode(df['definition'])\n",
    "\n",
    "pairwise_similarities=cosine_similarity(document_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dataframes = [similardocs_one(x,pairwise_similarities) for x in range(len(df['Index']))]\n",
    "outcome_bert = pd.concat(list_of_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_bert = outcome_bert.rename(columns = {'similarity_score':'similarity_score_bert','related_indicator':'related_indicator_bert'})\n",
    "                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60270, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_bert.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_bert_new = outcome_bert.groupby('indicator').head().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lidan/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5550732600732601, 0.44, 0.44217179311916155, None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(document_embeddings, df['goal_num'], test_size=0.2, random_state=42)\n",
    "clf = RandomForestClassifier(random_state=123)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "precision_recall_fscore_support(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/hannahz/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data into the format neede for doc2vec (tagged data )\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(doc), tags=[i]) for i, doc in enumerate(df['definition'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-3938c60db6a3>:11: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  document_embeddings[i]= model.docvecs[i]\n"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec(vector_size = 300, alpha = 0.025,min_count=5,dm =1,epochs = 50) #alpha learning rate, \n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "#train the model\n",
    "model.train(tagged_data,total_examples=model.corpus_count,# number of documents 246\n",
    "                        epochs=model.epochs)\n",
    "\n",
    "#gain the word embeddings from the model\n",
    "document_embeddings=np.zeros((246,300))\n",
    "for i in range(len(document_embeddings)):\n",
    "    document_embeddings[i]= model.docvecs[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.14669026,  0.27332506,  0.04717977, -0.02051441,  0.15534291,\n",
       "       -0.42399359,  0.19401339,  0.23166928, -0.07226435,  0.36478797,\n",
       "       -0.08121412, -0.6090855 , -0.28965861,  0.29935858,  0.09811122,\n",
       "        0.01581472,  0.44516975,  0.12168184,  0.05832525,  0.09200405,\n",
       "       -0.26412818,  0.17803343,  0.27489337,  0.2064822 ,  0.18687491,\n",
       "       -0.0213223 , -0.15532492,  0.16765897, -0.31469011, -0.26587889,\n",
       "        0.07205107,  0.1707761 ,  0.03952598,  0.15304857, -0.06317797,\n",
       "        0.32680348,  0.39701566, -0.49648869,  0.02341006,  0.05154991,\n",
       "       -0.16357231, -0.18082926, -0.23127496, -0.03820774,  0.35762927,\n",
       "        0.01140099, -0.04247866,  0.1342148 , -0.19258121,  0.32343706,\n",
       "       -0.14317697,  0.4729315 , -0.07715285,  0.16592571,  0.08860101,\n",
       "        0.12184708,  0.1068109 , -0.57704014, -0.1756933 ,  0.0500539 ,\n",
       "       -0.2759411 ,  0.10797344,  0.11577936, -0.20658927,  0.32633793,\n",
       "        0.11390201,  0.25454697,  0.06832714, -0.17576191, -0.14349182,\n",
       "       -0.14239326, -0.04498065,  0.50878316, -0.06667531,  0.09164602,\n",
       "        0.35725683,  0.11751126, -0.16451286, -0.43679744,  0.37497431,\n",
       "        0.31291744, -0.17968711, -0.00889854,  0.44554165,  0.04283009,\n",
       "       -0.03937959, -0.21900135, -0.01491895,  0.17639685,  0.29740483,\n",
       "        0.08696859, -0.1401049 , -0.08956702,  0.26464534, -0.19821243,\n",
       "        0.08976396,  0.18133499,  0.12551346,  0.07344799,  0.08103553,\n",
       "        0.08937183, -0.24329773,  0.20426898,  0.00609115, -0.22819372,\n",
       "       -0.21996796, -0.17067611,  0.36075997, -0.23812619,  0.06808598,\n",
       "       -0.21811257, -0.02264838, -0.44226775,  0.45498326,  0.15552163,\n",
       "        0.31406796, -0.31559917, -0.13256235,  0.09189191, -0.15363427,\n",
       "       -0.13301213, -0.02103388,  0.17474917, -0.19113104, -0.31784275,\n",
       "        0.20600446,  0.30697131, -0.35573918,  0.03111812,  0.09920567,\n",
       "        0.39983156,  0.64570028, -0.20319256,  0.13354515,  0.45304176,\n",
       "        0.08853428, -0.25593019, -0.24535511, -0.38656759,  0.09764166,\n",
       "        0.02537001, -0.4950648 , -0.44427213, -0.44599852,  0.40153545,\n",
       "       -0.27008584,  0.26536557, -0.47097886,  0.38916609,  0.18767637,\n",
       "        0.00855747, -0.50915825, -0.12258048,  0.1934495 , -0.05120336,\n",
       "       -0.07059591, -0.29871851, -0.11459293,  0.20988517,  0.11200218,\n",
       "        0.0322885 ,  0.21546127, -0.23747723,  0.21069747,  0.10243396,\n",
       "        0.14494026,  0.07823911, -0.03970656,  0.40069133,  0.55254406,\n",
       "        0.24110395,  0.04127087,  0.08499794,  0.07595471, -0.36192897,\n",
       "        0.42039275,  0.42828807,  0.01742497, -0.06683184, -0.31586146,\n",
       "        0.02521126,  0.16926332, -0.0890713 , -0.19595754,  0.27438149,\n",
       "        0.23697779,  0.16682735,  0.3623437 ,  0.3683382 , -0.0824018 ,\n",
       "       -0.16945989, -0.06402091, -0.45324472,  0.16084877,  0.17302366,\n",
       "       -0.02194516,  0.29019746,  0.0581513 ,  0.22982466,  0.02974225,\n",
       "       -0.46035787, -0.07619908,  0.13434835, -0.33446592, -0.19898184,\n",
       "       -0.0102094 ,  0.07473635,  0.19805659, -0.55227083, -0.11669824,\n",
       "       -0.01364121,  0.05142968, -0.0940778 , -0.41260996, -0.21918984,\n",
       "       -0.24090332, -0.38132215, -0.28207919, -0.11277524,  0.07782456,\n",
       "        0.03992717, -0.31026155, -0.35586241, -0.14885373, -0.20001633,\n",
       "       -0.07983736, -0.04833232, -0.07464228, -0.21473941, -0.17651431,\n",
       "        0.33925202, -0.16657563, -0.19328085,  0.37801689, -0.0429976 ,\n",
       "        0.37409794, -0.18889275,  0.21219403, -0.13603321,  0.07813363,\n",
       "        0.43993494, -0.20860374, -0.31460169, -0.27952498, -0.04093749,\n",
       "        0.1923293 ,  0.35639498,  0.03021186, -0.01799339,  0.41569492,\n",
       "        0.07806163,  0.38939694,  0.42348218,  0.07512631, -0.27107885,\n",
       "       -0.109107  ,  0.19715393,  0.06962999, -0.37810892, -0.41359043,\n",
       "        0.6911481 ,  0.08940514, -0.14935778, -0.31389493, -0.12681864,\n",
       "       -0.02311701,  0.35074601,  0.0485864 , -0.02134595, -0.04239006,\n",
       "       -0.04327339,  0.18267103,  0.01823262, -0.10188942,  0.41179416,\n",
       "        0.16234693,  0.16809887, -0.33418685,  0.0454284 , -0.09244456,\n",
       "        0.26589465, -0.32889748,  0.26635626,  0.2662667 , -0.02167751,\n",
       "       -0.03787715, -0.0480674 , -0.03914104,  0.09882955,  0.60197556,\n",
       "       -0.15258493,  0.40839773,  0.21442385, -0.3503474 ,  0.35969907,\n",
       "        0.21103017, -0.18199176,  0.02432886,  0.26024038,  0.07041576])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_embeddings[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_similarities=cosine_similarity(document_embeddings)\n",
    "\n",
    "list_of_dataframes = [similardocs_one(x,pairwise_similarities) for x in range(len(df['Index']))]\n",
    "outcome_doc2vec = pd.concat(list_of_dataframes)\n",
    "outcome_doc2vec = outcome_doc2vec.rename(columns = {'similarity_score':'similarity_score_doc2vec','related_indicator':'related_indicator_doc2vec'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indicator</th>\n",
       "      <th>related_indicator_doc2vec</th>\n",
       "      <th>similarity_score_doc2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1.1</td>\n",
       "      <td>1.2.1</td>\n",
       "      <td>0.836483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1.1</td>\n",
       "      <td>11.1.1</td>\n",
       "      <td>0.789737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.1.1</td>\n",
       "      <td>3.3.1</td>\n",
       "      <td>0.736435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1.1</td>\n",
       "      <td>11.6.2</td>\n",
       "      <td>0.727911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1.1</td>\n",
       "      <td>8.5.2</td>\n",
       "      <td>0.709573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  indicator related_indicator_doc2vec  similarity_score_doc2vec\n",
       "0     1.1.1                     1.2.1                  0.836483\n",
       "1     1.1.1                    11.1.1                  0.789737\n",
       "2     1.1.1                     3.3.1                  0.736435\n",
       "3     1.1.1                    11.6.2                  0.727911\n",
       "4     1.1.1                     8.5.2                  0.709573"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_doc2vec_new = outcome_doc2vec.groupby('indicator').head().reset_index(drop=True)\n",
    "outcome_doc2vec_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lidan/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6265555555555555, 0.48, 0.48273726273726275, None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(document_embeddings, df['goal_num'], test_size=0.2, random_state=42)\n",
    "clf = RandomForestClassifier(random_state=123)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "precision_recall_fscore_support(y_test, y_pred, average='weighted')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a new cleaned column, which contain definition and index information\n",
    "df['cleaned'] = df[['definition','Index']].apply(lambda x: ','.join(x.astype(str)), axis=1)\n",
    "# get the data into the format neede for word2vec (list of list data )\n",
    "sent = [row.split(',') for row in df['cleaned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sent, min_count=1,workers=3, vector_size = 300, window =3, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gain the word embeddings from the model\n",
    "document_embeddings_word2vec=np.zeros((246,300))\n",
    "for i in range(len(document_embeddings_word2vec)):\n",
    "    document_embeddings_word2vec[i]= model.wv[df['Index'].iloc[i]].reshape((1,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_similarities=cosine_similarity(document_embeddings)\n",
    "\n",
    "list_of_dataframes_word2vec = [similardocs_one(x,pairwise_similarities) for x in range(len(df['Index']))]\n",
    "outcome_word2vec = pd.concat(list_of_dataframes_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indicator</th>\n",
       "      <th>related_indicator_word2vec</th>\n",
       "      <th>similarity_score_word2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1.1</td>\n",
       "      <td>1.2.1</td>\n",
       "      <td>0.824847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1.1</td>\n",
       "      <td>11.1.1</td>\n",
       "      <td>0.746653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.1.1</td>\n",
       "      <td>10.2.1</td>\n",
       "      <td>0.692284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1.1</td>\n",
       "      <td>8.5.2</td>\n",
       "      <td>0.690044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1.1</td>\n",
       "      <td>11.6.2</td>\n",
       "      <td>0.689793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  indicator related_indicator_word2vec  similarity_score_word2vec\n",
       "0     1.1.1                      1.2.1                   0.824847\n",
       "1     1.1.1                     11.1.1                   0.746653\n",
       "2     1.1.1                     10.2.1                   0.692284\n",
       "3     1.1.1                      8.5.2                   0.690044\n",
       "4     1.1.1                     11.6.2                   0.689793"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_word2vec = outcome_word2vec.rename(columns = {'similarity_score':'similarity_score_word2vec','related_indicator':'related_indicator_word2vec'})\n",
    "outcome_word2vec_new = outcome_word2vec.groupby('indicator').head().reset_index(drop=True)\n",
    "outcome_word2vec_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outcome_bert_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-6a9a87336d5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# merge tf-idf and bert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutcome_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutcome_tf_idf_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutcome_bert_new\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# add doc2vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutcome_full\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutcome_full\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutcome_doc2vec_new\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# add word2vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'outcome_bert_new' is not defined"
     ]
    }
   ],
   "source": [
    " # merge tf-idf and bert\n",
    "outcome_full = pd.concat([outcome_tf_idf_new,outcome_bert_new],axis=1)\n",
    "# add doc2vec\n",
    "outcome_full= pd.concat([outcome_full,outcome_doc2vec_new],axis=1)\n",
    "# add word2vec\n",
    "outcome_full= pd.concat([outcome_full,outcome_word2vec_new],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outcome_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-170d815e69c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m outcome_full = outcome_full[['indicator', 'related_indicator_tf_idf', 'similarity_score_tf_idf',\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0;34m'related_indicator_doc2vec'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'similarity_score_doc2vec'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         'related_indicator_word2vec', 'similarity_score_word2vec']]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'outcome_full' is not defined"
     ]
    }
   ],
   "source": [
    "outcome_full = outcome_full[['indicator', 'related_indicator_tf_idf', 'similarity_score_tf_idf',\n",
    "        'related_indicator_doc2vec', 'similarity_score_doc2vec',\n",
    "        'related_indicator_word2vec', 'similarity_score_word2vec']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indicator</th>\n",
       "      <th>related_indicator_tf_idf</th>\n",
       "      <th>similarity_score_tf_idf</th>\n",
       "      <th>related_indicator_doc2vec</th>\n",
       "      <th>similarity_score_doc2vec</th>\n",
       "      <th>related_indicator_word2vec</th>\n",
       "      <th>similarity_score_word2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1.1</td>\n",
       "      <td>1.2.1</td>\n",
       "      <td>0.414994</td>\n",
       "      <td>1.2.1</td>\n",
       "      <td>0.875192</td>\n",
       "      <td>1.2.1</td>\n",
       "      <td>0.858479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1.1</td>\n",
       "      <td>10.2.1</td>\n",
       "      <td>0.193975</td>\n",
       "      <td>11.1.1</td>\n",
       "      <td>0.871263</td>\n",
       "      <td>11.1.1</td>\n",
       "      <td>0.828153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.1.1</td>\n",
       "      <td>10.7.4</td>\n",
       "      <td>0.158748</td>\n",
       "      <td>11.6.2</td>\n",
       "      <td>0.761997</td>\n",
       "      <td>11.6.2</td>\n",
       "      <td>0.700170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1.1</td>\n",
       "      <td>16.8.1</td>\n",
       "      <td>0.155508</td>\n",
       "      <td>17.3.2</td>\n",
       "      <td>0.753025</td>\n",
       "      <td>3.3.2</td>\n",
       "      <td>0.699983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1.1</td>\n",
       "      <td>16.b.1</td>\n",
       "      <td>0.152244</td>\n",
       "      <td>3.3.1</td>\n",
       "      <td>0.748638</td>\n",
       "      <td>3.3.1</td>\n",
       "      <td>0.692252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.2.1</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>0.414994</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>0.875192</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>0.858479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.2.1</td>\n",
       "      <td>1.b.1</td>\n",
       "      <td>0.153754</td>\n",
       "      <td>11.1.1</td>\n",
       "      <td>0.844428</td>\n",
       "      <td>9.1.1</td>\n",
       "      <td>0.806331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.2.1</td>\n",
       "      <td>1.a.1</td>\n",
       "      <td>0.148588</td>\n",
       "      <td>9.1.1</td>\n",
       "      <td>0.812365</td>\n",
       "      <td>11.1.1</td>\n",
       "      <td>0.785132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.2.1</td>\n",
       "      <td>9.1.1</td>\n",
       "      <td>0.142980</td>\n",
       "      <td>3.9.3</td>\n",
       "      <td>0.720787</td>\n",
       "      <td>11.6.2</td>\n",
       "      <td>0.740767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.2.1</td>\n",
       "      <td>1.2.2</td>\n",
       "      <td>0.137517</td>\n",
       "      <td>3.6.1</td>\n",
       "      <td>0.717430</td>\n",
       "      <td>3.6.1</td>\n",
       "      <td>0.731003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  indicator related_indicator_tf_idf  similarity_score_tf_idf  \\\n",
       "0     1.1.1                    1.2.1                 0.414994   \n",
       "1     1.1.1                   10.2.1                 0.193975   \n",
       "2     1.1.1                   10.7.4                 0.158748   \n",
       "3     1.1.1                   16.8.1                 0.155508   \n",
       "4     1.1.1                   16.b.1                 0.152244   \n",
       "5     1.2.1                    1.1.1                 0.414994   \n",
       "6     1.2.1                    1.b.1                 0.153754   \n",
       "7     1.2.1                    1.a.1                 0.148588   \n",
       "8     1.2.1                    9.1.1                 0.142980   \n",
       "9     1.2.1                    1.2.2                 0.137517   \n",
       "\n",
       "  related_indicator_doc2vec  similarity_score_doc2vec  \\\n",
       "0                     1.2.1                  0.875192   \n",
       "1                    11.1.1                  0.871263   \n",
       "2                    11.6.2                  0.761997   \n",
       "3                    17.3.2                  0.753025   \n",
       "4                     3.3.1                  0.748638   \n",
       "5                     1.1.1                  0.875192   \n",
       "6                    11.1.1                  0.844428   \n",
       "7                     9.1.1                  0.812365   \n",
       "8                     3.9.3                  0.720787   \n",
       "9                     3.6.1                  0.717430   \n",
       "\n",
       "  related_indicator_word2vec  similarity_score_word2vec  \n",
       "0                      1.2.1                   0.858479  \n",
       "1                     11.1.1                   0.828153  \n",
       "2                     11.6.2                   0.700170  \n",
       "3                      3.3.2                   0.699983  \n",
       "4                      3.3.1                   0.692252  \n",
       "5                      1.1.1                   0.858479  \n",
       "6                      9.1.1                   0.806331  \n",
       "7                     11.1.1                   0.785132  \n",
       "8                     11.6.2                   0.740767  \n",
       "9                      3.6.1                   0.731003  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_full =  outcome_full.iloc[: , 3:]\n",
    "outcome_full.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_full.to_excel('method_outcome.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
